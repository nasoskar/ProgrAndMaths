{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7f4f4a",
   "metadata": {},
   "source": [
    "## A simple notebook to test some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7afe7e5",
   "metadata": {},
   "source": [
    "#### Activation functions: sigmoid and ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459e72b",
   "metadata": {},
   "source": [
    "Sigmoid and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fedd5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999997739675702 2.260319188887599e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "\n",
    "    s = 1/(1 + np.exp(-x))\n",
    "\n",
    "    return s\n",
    "\n",
    "def derivative_sigmoid(s):\n",
    "\n",
    "    ds = s*(1-s)\n",
    "\n",
    "    return ds\n",
    "\n",
    "w = [1,2]\n",
    "x = [2,4]\n",
    "b = 3\n",
    "z = np.dot(w,x) + b\n",
    "a = sigmoid(z)\n",
    "da = derivative_sigmoid(a)\n",
    "print(a,da)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ef17c",
   "metadata": {},
   "source": [
    "ReLU and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c95356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def derivative_relu(x):\n",
    "    return 1 * (x>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c803de9",
   "metadata": {},
   "source": [
    "Now let's implement the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24737ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(vector):\n",
    "    e = np.exp(vector)\n",
    "    return e / e.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_softmax(vector):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_dropout(x, p):\n",
    "    # p = dropout probability\n",
    "    mask = (np.random.rand(*x.shape) > p).astype(float)\n",
    "    x_dropped = (x * mask)/(1 - p) # the actual dropout\n",
    "    return x_dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9120e733",
   "metadata": {},
   "source": [
    "### Implement a fully parametrizable neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cc2a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     species  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "145        2  \n",
       "146        2  \n",
       "147        2  \n",
       "148        2  \n",
       "149        2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['species'] = iris.target\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcf7f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "22                 4.6               3.6                1.0               0.2\n",
       "15                 5.7               4.4                1.5               0.4\n",
       "65                 6.7               3.1                4.4               1.4\n",
       "11                 4.8               3.4                1.6               0.2\n",
       "42                 4.4               3.2                1.3               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "71                 6.1               2.8                4.0               1.3\n",
       "106                4.9               2.5                4.5               1.7\n",
       "14                 5.8               4.0                1.2               0.2\n",
       "92                 5.8               2.6                4.0               1.2\n",
       "102                7.1               3.0                5.9               2.1\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1a01f",
   "metadata": {},
   "source": [
    "## Create a NN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "# just 4 samples\n",
    "X = np.array(X_train)\n",
    "\n",
    "# target values \n",
    "y = np.array(y_train).T \n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    #hidden layer (sigmoid, relu)\n",
    "    #output layer (softmax)\n",
    "\n",
    "    def __init__(self, activation_function, no_of_input_nodes, no_of_hidden_nodes, no_of_output_nodes, n_epochs,lambda1,lambda2):\n",
    "        self.hidden_layers = len(no_of_hidden_nodes)\n",
    "        self.activation_function = activation_function\n",
    "        self.no_of_input_nodes = no_of_input_nodes # as many as the dataset's features\n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes # no fixed number, needs tuning\n",
    "        self.no_of_output_nodes = no_of_output_nodes # as many as the output classes\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lambda1 = lambda1 #lambda variable for L1 regularisation\n",
    "        self.lambda2 = lambda2 #lambda variable for L2 regularisation\n",
    "\n",
    "        self.z_values = [] # need to store for backprop\n",
    "        self.a_values = []   # need to store for backprop, first value is the actual data\n",
    "\n",
    "        self.weights, self.biases = self.weights_and_bias()\n",
    "\n",
    "    def weights_and_bias(self):\n",
    "        layers = [self.no_of_input_nodes] + self.no_of_hidden_nodes + [self.no_of_output_nodes] #e.g. [2,3,5,2]\n",
    "        weights = [] #TODO: weight and bias proper initialization (xavier)\n",
    "        biases = []\n",
    "        for i in range(len((layers))-1):\n",
    "\n",
    "            n_in = layers[i]\n",
    "            n_out = layers[i+1]\n",
    "\n",
    "            weights.append(2*np.random.random((n_in,n_out)) - 1)\n",
    "            biases.append(np.zeros((1, n_out)))\n",
    "        return weights, biases\n",
    "\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "\n",
    "        #first hidden layer needs to have the actual data\n",
    "        #all other hidden layers take the result from the previous layer\n",
    "        a = X\n",
    "        self.a_values.append(a) # save for backprop\n",
    "        \n",
    "        for layer in range(self.hidden_layers):\n",
    "\n",
    "            W = self.weights[layer]\n",
    "            b = self.biases[layer]\n",
    "            z = np.dot(a, W) + b\n",
    "            self.z_values.append(z) # save for backprop\n",
    "\n",
    "            if self.activation_function =='sigmoid':\n",
    "                a = sigmoid(z)\n",
    "            elif self.activation_function =='relu':\n",
    "                a = relu(z)\n",
    "            print(f'Shape of layer: {a.shape}')\n",
    "\n",
    "            #implementing inverted dropout\n",
    "            a = inverted_dropout(a, 0.5) #TODO: if testing, we don't do dropout\n",
    "            #TODO: do we add the same p for all neurons and layers?\n",
    "\n",
    "            self.a_values.append(a) # save for backprop\n",
    "\n",
    "        #---Output Layer---\n",
    "        W = self.weights[-1]\n",
    "        b = self.biases[-1]\n",
    "        z = np.dot(a, W) + b\n",
    "        self.z_values.append(z) # save for backprop\n",
    "        a = softmax(z)\n",
    "        self.a_values.append(a) # save for backprop\n",
    "        print(f'Shape of output layer: {a.shape}')\n",
    "        return a\n",
    "        \n",
    "\n",
    "    def backward_pass():\n",
    "        pass\n",
    "\n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "        '''\n",
    "        Cross entropy loss for multi-class classification with L1 and L2 regularization\n",
    "        '''\n",
    "\n",
    "        # number of samples\n",
    "        N = y_true.shape[0]\n",
    "        \n",
    "        correct_probs = y_pred[np.arange(N), y_true] \n",
    "    \n",
    "        # loss = average of -log(p) whre p is the predicted probability of the correct class\n",
    "        loss = -np.sum(np.log(correct_probs)) / N\n",
    "\n",
    "        l1_loss = self.lambda1* np.sum(np.abs(self.weights)) #TODO: needs to be added in weight update in backprop too\n",
    "        l2_loss = self.lambda2* np.sum(np.abs(self.weights**2))\n",
    "\n",
    "        return loss + l1_loss + l2_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ee072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of layer: (120, 3)\n",
      "Shape of layer: (120, 4)\n",
      "Shape of output layer: (120, 3)\n"
     ]
    }
   ],
   "source": [
    "#TODO: run the forward pass in epochs\n",
    "#n_epochs = 500\n",
    "#for epoch in range(n_epochs):\n",
    "\n",
    "\n",
    "#Param tuning:\n",
    "#lambda1 and lambda 2 can be from 0 to 1\n",
    "nn = NeuralNetwork('sigmoid',4,[3,4],3,500,0.2,0.3)\n",
    "\n",
    "# Forward pass\n",
    "y_pred = nn.forward_pass(X_train)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.compute_loss(y_pred, y_train)\n",
    "\n",
    "# Backward pass\n",
    "nn.backward_pass(X_train, y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc12d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010344313351809925 0.0051952548612967265\n",
      "[0.00841486 0.00836609 0.00831748 0.00839032 0.0084097 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.min(y_pred), np.max(y_pred))\n",
    "print(np.sum(y_pred, axis=1)[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa244a",
   "metadata": {},
   "source": [
    "### Backward Pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
